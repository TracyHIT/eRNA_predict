###########Train and test xgboost model #############
#' First train in 5-fold and validated to select the best parameter(nroundsi,max_depthi,etai).
#'
#' Then train the model with the best parameter and test the model 5 times
#' output: XGBoost model saved in Result/Model/, error_matrix saved in Result/Summary/
#'
#' @param data_file: the matrix Rdata generated by make_model_feature_index, last colomn is Y
#' @param cell: the cell type name
#' @param Feature_index: the feature index, please refer to make_model_feature_index
xgb_train_self_tuning_fuzz <-function(data_file,cell,Feature_index=3)
{
  library("xgboost")
  library("pROC")
  library("caret")
  library("doParallel")
  library("foreach")
  load(data_file)
  source("Script/make_model_feature_index.R")
  accepts <- Freature_index_make(accepts,Feature_index)
  accepts <- accepts[which(accepts$Ac_Y==0 | accepts$Ac_Y==1),]

  
  
  err=NULL
  nroundsi = rep(c(50,100,150,200,250),12)
  max_depthi =  c(rep(4,15),rep(6,15),rep(8,15),rep(10,15))
  etai = rep(c(rep(0.1,5),rep(0.2,5),rep(0.3,5)),4)
  
  ######k-zhe
  len <- nrow(accepts)
  k = 5
  mysplit = function(k,len){
    pool = c(1:len)
    seg = as.integer(len/k)
    train = as.data.frame(matrix(nrow = (len - seg)))
    test = as.data.frame(matrix(nrow = seg))
    for (i in 1 : k){
      ctest = sample(pool,seg,replace = FALSE)
      train[i] = setdiff(c(1:len),ctest)
      test[i] = ctest
      pool = setdiff(pool,ctest)
    }
    out = list(one = train, two = test)
    return(out)
  }
  train_index = (mysplit(k,len))$one
  test_index = (mysplit(k,len))$two
  
  for(j in 1:length(etai))
  {
    print(paste0("Test_etai: ",etai[j]))
    err_temp <- NULL
    for(i in 1:5)#5æŠ˜
    {
      print(paste0("Test_etai: ",etai[j],"_________K:",i))
      train <- accepts[ unlist(train_index[i]),]
      test <- accepts[ unlist(test_index[i]),]#20% test
      
      sample_count <-min(summary(as.factor(train$Ac_Y)))
      print(summary(as.factor(train$Ac_Y)))
      sample_index <- sample(c(1:length(train$Ac_Y))[which(train$Ac_Y==0)],sample_count)
      train_DownSample <- data.frame(train[c(sample_index,which(train$Ac_Y==1)),])
      dtrain <-xgb.DMatrix(data = as.matrix(train_DownSample[,-ncol(train_DownSample)]),label=as.numeric(train_DownSample[,ncol(train_DownSample)]))
      temp_gbx <- xgboost(data= dtrain,max_depth=max_depthi[j],eta=etai[j],objective='binary:logistic',nrounds = nroundsi[j])
      
      dtest <- xgb.DMatrix(data = as.matrix(test[,-ncol(train_DownSample)]),label=as.numeric(test[,ncol(train_DownSample)]))
      pre_xgb = round(predict(temp_gbx,newdata = dtest))
      Fred <- table(test[,ncol(train_DownSample)],pre_xgb,dnn=c("True","Predict"))
      err_temp <- c(err_temp,1-sum(diag(Fred))/sum(Fred))
      print(paste0("Test_etai: ",etai[j],"_________K:",i,"test end!",err_temp))
    }
    err <- c(err,mean(err_temp))
    print(j)
    print(err)
  }
  
  nroundsi =  nroundsi[which.min(err)]
  max_depthi = max_depthi[which.min(err)]
  etai= etai[which.min(err)]
  
  error_matrix <-matrix(0,nrow=20,ncol=8)
  colnames(error_matrix) <- c("MCC","auc","sensitivities","specificities","T0P0","T0P1","T1P0","T1P1")
  for(i in 1:5)
  {
    train <- accepts[ unlist(train_index[i]),]
    test <- accepts[ unlist(test_index[i]),]#20% test

    sample_count <-min(summary(as.factor(train$Ac_Y)))
    print(summary(as.factor(train$Ac_Y)))
    sample_index <- sample(c(1:length(train$Ac_Y))[which(train$Ac_Y==0)],sample_count)
    train_DownSample <- data.frame(train[c(sample_index,which(train$Ac_Y==1)),])
    dtrain <-xgb.DMatrix(data = as.matrix(train_DownSample[,-ncol(train_DownSample)]),label=as.numeric(train_DownSample[,ncol(train_DownSample)]))
    xgb<- xgboost(data=  dtrain,max_depth=max_depthi,eta=etai,objective='binary:logistic',nrounds = nroundsi)
    save(xgb,file = paste0("Result/Model/",cell,"_ActiveP_",Feature_index,"_",i,"_xgb_fuzz.Rdata"))

    dtest <-xgb.DMatrix(data = as.matrix(test[,-ncol(train_DownSample)]),label=as.numeric(test[,ncol(train_DownSample)]))
    pre_xgb = round(predict(xgb,newdata = dtest))
    Fred=table(test[,ncol(train_DownSample)],pre_xgb,dnn=c("True","Predict"))
    library(pROC)
    xgboost_roc <- roc(test[,ncol(train_DownSample)],as.numeric(pre_xgb))
    error_matrix[i,2] <- xgboost_roc$auc
    error_matrix[i,3] <-  xgboost_roc$sensitivities[2]
    error_matrix[i,4] <-  xgboost_roc$specificities[2]
    error_matrix[i,5] <-  Fred[1,1]#Ture0,Pred0  TN
    error_matrix[i,6] <-  Fred[1,2]#Ture0,Pred1  FP
    error_matrix[i,7] <-  Fred[2,1]#Ture1,Pred0  FN
    error_matrix[i,8] <-  Fred[2,2]#Ture1,Pred1  TP
    error_matrix[i,1]<- (Fred[2,2]*Fred[1,1] - Fred[1,2]*Fred[2,1])/(sqrt(Fred[2,2]+Fred[1,2])*sqrt(Fred[2,2]+Fred[2,1])*sqrt(Fred[1,1]+Fred[1,2])*sqrt(Fred[1,1]+Fred[2,1]))
  }
  write.csv(error_matrix,file  = paste0("Result/Summary/",cell,"_Active_P_",Feature_index,"_xgboost_fuzz.csv"))
}

###########Corss Test XGBoost model 5 Times#############
#'
#' output: test error_matrix saved in "Result/Summary/Coss_"
#'
#' @param model_cell: the cell type name of model
#' @param test_Cell: the cell type name of test
#' @param Feature_index: the feature index of model
#' @param test_Data: the test data about the test cell type
cross_Cell_xgb_fuzz <- function(model_cell="GM12878",test_Cell="K562",Feature_index,test_Data)
{
  library(xgboost)
  load(test_Data)
  source("Script/make_model_feature_index.R")
  accepts <- Freature_index_make(accepts,Feature_index)
  accepts <- accepts[which(accepts$Ac_Y==0 | accepts$Ac_Y==1),]
  error_matrix <-matrix(0,nrow=20,ncol=4)
  colnames(error_matrix) <- c("","auc","sensitivities","specificities")
  for(i in 1:5)
  {
    load(paste0("Result/Model/",model_cell,"_ActiveP_",Feature_index,"_",i,"_xgb_fuzz.Rdata"))
    test <- accepts
    names(error_matrix) <- c("","auc","sensitivities","specificities")

    dtest <-xgb.DMatrix(data = as.matrix(test[,-ncol(test)]),label=as.numeric(test[,ncol(test)]))
    pre_xgb = round(predict(xgb,newdata = dtest))

    library(pROC)
    xgboost_roc <- roc(test[,ncol(test)],as.numeric(pre_xgb))
    error_matrix[i,2] <-  xgboost_roc$auc
    error_matrix[i,3] <-  xgboost_roc$sensitivities[2]
    error_matrix[i,4] <-  xgboost_roc$specificities[2]
  }
  write.csv(error_matrix,file = paste0("Result/Summary/Coss_",model_cell,"_",test_Cell,"_",Feature_index,"_ActiveP_xgb_fuzz.csv"))
}



